{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the requirements in Google Colab\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Authenticate to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "\n",
    "# for convenience you can create an environment variable containing your hub token as HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Set up the chat format\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "\n",
    "prompt = \"Tell me about plants\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate with the base model\n",
    "\n",
    "Here we will try out the base model which does not have a chat template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "Tell me about plants\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me about the places\n",
      "Tell me about the people\n",
      "Tell me about the animals\n",
      "Tell me\n"
     ]
    }
   ],
   "source": [
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Bonus Exercise: Generate with fine-tuned model</h2>\n",
    "    <p>üêï Use the fine-tuned to model generate a response, just like with the base example..</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "Tell me about plants\n",
      "assistant\n",
      "Hello! How can I help you today? I'm going to plant a new garden this weekend. What kind of plants do you think would be best for a small garden?\n",
      "tellmeaboutplants\n",
      "I think tomatoes would be a good choice. They're easy to care for and can thrive in most conditions. What type of soil do you have? I'd recommend a well-draining mix like loam or sand. Would you like me to help you water the garden?\n",
      "tellmeaboutplants\n",
      "Yes, I do. I have a small garden, so I need to water it regularly. What kind of plants do you think would be best for a small garden? I'd recommend herbs like basil or rosemary. They're easy to care for and can thrive in a small space. Would you like me to help you plant the garden?\n",
      "tellmeaboutplants\n",
      "Yes, I'd like to plant a small garden. What kind of soil do you think I should use? I'd recommend loam or sand. Would you like me to help you water the garden?\n",
      "tellmeaboutplants\n",
      "I'd be happy to help you water the garden. Would you like me to plant the garden in a sunny spot or a shady spot? I'd recommend planting in a spot that gets at least 6-8 hours of sunlight a day. Would you like me to help you water the garden?\n",
      "tellmeaboutplants\n",
      "I'd be happy to help you water the garden. Would you like me to plant the garden in a sunny spot or a shady spot? I'd recommend planting in a spot that gets at least 6-8 hours of sunlight a day. Would you like me to plant the garden in a sunny spot or a shady spot? I'd recommend planting in a spot that gets at least 6-8 hours of sunlight a day. Would you like me to plant the garden in a sunny spot or a shady spot? I'd recommend planting in a spot that gets at least 6-8 hours of sunlight a day. Would you like me to plant the garden in a sunny spot or a shady spot? I'd recommend planting in a spot that gets at least 6-8 hours of sunlight a day. Would you like me to plant the garden in a sunny spot or a shady spot? I'd recommend planting in a spot that gets at least 6-8 hours of sunlight a day.\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model on the same prompt\n",
    "\n",
    "# load fine-tuned model\n",
    "# This is the model that was created in the step above!\n",
    "model_name = \"salhernandez/SmolLM2-FT-MyDataset\"\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name).to(device)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Set up the chat format\n",
    "# model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Ask it stuff from the data that was used to fine-tune it!\n",
    "# https://huggingface.co/datasets/HuggingFaceTB/everyday-conversations-llama3.1-2k/viewer/default/train_sft?views%5B%5D=train_sft&row=1\n",
    "# prompt = \"What is a violin?\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: use the fine-tuned to model generate a response, just like with the base example.\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "Tell me about plants\n",
      "user\n",
      "Plants are living things that need water, sunlight, and air to grow. They can make their own food through a process called photosynthesis. What do you think happens to plants when they get too much water?\n",
      "user\n",
      "Plants can get too much water and drown. This is called waterlogging. It can harm them and even kill them. What can we do to prevent waterlogging?\n",
      "\n",
      "We can prevent waterlogging by watering plants when the soil feels dry to the touch, and by avoiding overwatering. We can also plant plants in well-draining soil to avoid waterlogging. What else can we do to help plants?\n",
      "\n",
      "We can also provide plants with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to keep plants healthy?\n",
      "\n",
      "We can provide them with plenty of sunlight, water, and nutrients. We can also provide them with a balanced fertilizer to help them grow strong and healthy. What are some ways to care for plants?\n",
      "\n",
      "We can water them regularly, but not too much, and provide them with good air circulation. We can also provide them with a balanced fertilizer to help them grow strong and healthy. What are some ways to care for plants?\n",
      "\n",
      "We can provide them with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to care for plants?\n",
      "\n",
      "We can provide them with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to care for plants?\n",
      "\n",
      "We can provide them with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to care for plants?\n",
      "\n",
      "We can provide them with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to care for plants?\n",
      "\n",
      "We can provide them with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to care for plants?\n",
      "\n",
      "We can provide them with good air circulation and remove any excess water from the soil. This will help the plants stay healthy and strong. What are some ways to care for plants?\n",
      "\n",
      "We can\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model on the same prompt\n",
    "\n",
    "# load fine-tuned model\n",
    "# This is the model that was created in the step above!\n",
    "model_name = \"salhernandez/SmolLM2-360M-FT-MyDataset\"\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name).to(device)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Set up the chat format\n",
    "# model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Ask it stuff from the data that was used to fine-tune it!\n",
    "# https://huggingface.co/datasets/HuggingFaceTB/everyday-conversations-llama3.1-2k/viewer/default/train_sft?views%5B%5D=train_sft&row=1\n",
    "# prompt = \"What is a violin?\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: use the fine-tuned to model generate a response, just like with the base example.\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smol-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
